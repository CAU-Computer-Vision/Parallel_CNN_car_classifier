{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torchlayers as tl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((120, 120)), transforms.ToTensor()])\n",
    "\n",
    "# datas = torchvision.datasets.ImageFolder(root = './data/kcar/lights', transform = trans)\n",
    "# train_size = int(len(datas) * 0.8)\n",
    "# test_size = len(datas) - train_size\n",
    "# train_sets, test_sets = torch.utils.data.random_split(datas, [train_size, test_size])\n",
    "\n",
    "# edge_datas = torchvision.datasets.ImageFolder(root = './data/kcar_edge', transform = trans)\n",
    "# edge_train_size = int(len(edge_datas) * 0.8)\n",
    "# edge_test_size = len(edge_datas) - edge_train_size\n",
    "# edge_train_sets, edge_test_sets = torch.utils.data.random_split(edge_datas, [edge_train_size, edge_test_size])\n",
    "\n",
    "edge_train_sets = torchvision.datasets.ImageFolder(root = './data/kcar_edge/lights', transform = trans)\n",
    "edge_test_sets = torchvision.datasets.ImageFolder(root = './data/kcar_edge/darks', transform = trans)\n",
    "train_sets = torchvision.datasets.ImageFolder(root = './data/kcar/lights', transform = trans)\n",
    "test_sets = torchvision.datasets.ImageFolder(root = './data/kcar/darks', transform = trans)\n",
    "labels = train_sets.classes\n",
    "print(edge_train_sets)\n",
    "print(train_sets)\n",
    "# print(test_sets)\n",
    "# print(edge_test_sets)\n",
    "\n",
    "# print(len(labels))\n",
    "# for i in range(4):\n",
    "#     img, label = train_sets[i]\n",
    "#     print(labels[label])\n",
    "#     plt.subplot(241 + i)\n",
    "#     plt.imshow(np.clip(img.permute(1,2,0),0,1))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    # save_image(img, str(i)+'_.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_sets, batch_size = 32, num_workers = 2)\n",
    "edge_train_loader = DataLoader(edge_train_sets, batch_size = 32, num_workers = 2)\n",
    "test_loader = DataLoader(test_sets, batch_size = 32)\n",
    "edge_test_loader = DataLoader(edge_test_sets, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(\n",
    "    tl.Conv(64),  # specify ONLY out_channels\n",
    "    tl.ReLU(),  # use torch.nn wherever you wish\n",
    "    tl.BatchNorm(),  # BatchNormNd inferred from input\n",
    "    tl.Conv(128),  # Default kernel_size equal to 3\n",
    "    tl.ReLU(),\n",
    "    tl.MaxPool(),\n",
    "    tl.Conv(256, kernel_size=11),  # \"same\" padding as default\n",
    "    # tl.ReLU(),\n",
    "    tl.GlobalMaxPool(),\n",
    "    tl.Linear(52),  # Output for 52 classes\n",
    ")\n",
    "model1 = tl.build(model1, torch.randn(1, 3, 120, 120))\n",
    "model1.cuda()\n",
    "model2 = torch.nn.Sequential(\n",
    "    tl.Conv(64),  # specify ONLY out_channels\n",
    "    torch.nn.ReLU(),  # use torch.nn wherever you wish\n",
    "    tl.BatchNorm(),  # BatchNormNd inferred from input\n",
    "    tl.Conv(128),  # Default kernel_size equal to 3\n",
    "    tl.ReLU(),\n",
    "    tl.MaxPool(),\n",
    "    tl.Conv(256, kernel_size=11),  # \"same\" padding as default\n",
    "    # tl.ReLU(),\n",
    "    tl.GlobalMaxPool(),\n",
    "    tl.Linear(52),  # Output for 52 classes\n",
    ")\n",
    "model2 = tl.build(model2, torch.randn(1, 3, 28, 28))\n",
    "model2.cuda()\n",
    "\n",
    "# one_way_model = torch.nn.Sequential(\n",
    "#     tl.Conv(64),  # specify ONLY out_channels\n",
    "#     tl.ReLU(),  # use torch.nn wherever you wish\n",
    "#     tl.BatchNorm(),  # BatchNormNd inferred from input\n",
    "#     tl.Conv(128),  # Default kernel_size equal to 3\n",
    "#     tl.ReLU(),\n",
    "#     tl.Conv(256, kernel_size=11),  # \"same\" padding as default\n",
    "#     tl.GlobalMaxPool(),  # Known from Keras\n",
    "#     tl.Linear(52),  # Output for 2 classes\n",
    "# )\n",
    "# one_way_model = tl.build(one_way_model, torch.randn(1, 3, 28, 28))\n",
    "# one_way_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.fc = nn.Linear(104, 52)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        # print(x1.shape, x.shape, self.num_flat_features(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        x = self.fc(x)\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):  \n",
    "        size = x.size()[1:] \n",
    "        num_features = 1 \n",
    "        for s in size: \n",
    "            num_features *= s \n",
    "        return num_features\n",
    "\n",
    "model = MyEnsemble(model1, model2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,5,8], gamma=0.1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is available')\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "print(len(train_loader))\n",
    "for epoch in range(10):\n",
    "    for index, ((data, target), (edge_data, edge_target)) in enumerate(zip(train_loader, edge_train_loader)):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        edge_data, edge_target = edge_data.cuda(), edge_target.cuda()\n",
    "\n",
    "        output = model(data, edge_data)\n",
    "        optimizer.zero_grad()\n",
    "        print(target)\n",
    "        print(output)\n",
    "        loss = criterion(output, target)\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            print(\"loss of {} epoch, {} index : {}\".format(epoch, index, loss.item()))\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()  # 학습\n",
    "print(len(train_loader))\n",
    "for epoch in range(10): \n",
    "    optimizer.zero_grad()  # 기울기 초기화\n",
    "    for index, ((data, target), (edge_data, edge_target)) in enumerate(zip(train_loader, edge_train_loader)):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        edge_data, edge_target = edge_data.cuda(), edge_target.cuda()\n",
    "\n",
    "        output = model(data, edge_data)\n",
    "        loss = criterion(output, target)\n",
    "        # print(loss.item())\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            print(\"loss of {} epoch, {} index : {}\".format(epoch, index, loss.item()))\n",
    "    scheduler.step()    \n",
    "    print(\"scheduler-step\")\n",
    "    print(\"-----\") "
   ]
  }
 ]
}
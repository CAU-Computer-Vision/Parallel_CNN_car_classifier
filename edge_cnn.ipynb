{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torchlayers as tl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((120, 120)), transforms.ToTensor()])\n",
    "trans_gray = transforms.Compose([transforms.Resize((120, 120)), transforms.ToTensor(), transforms.Grayscale()])\n",
    "\n",
    "\n",
    "# datas = torchvision.datasets.ImageFolder(root = './data/kcar/lights', transform = trans)\n",
    "# train_size = int(len(datas) * 0.8)\n",
    "# test_size = len(datas) - train_size\n",
    "# train_sets, test_sets = torch.utils.data.random_split(datas, [train_size, test_size])\n",
    "\n",
    "edge_datas = torchvision.datasets.ImageFolder(root = './data/kcar_edge/lights', transform = trans_gray)\n",
    "edge_train_size = int(len(edge_datas) * 0.8)\n",
    "edge_test_size = len(edge_datas) - edge_train_size\n",
    "edge_train_sets, edge_test_sets = torch.utils.data.random_split(edge_datas, [edge_train_size, edge_test_size])\n",
    "\n",
    "# edge_train_sets = torchvision.datasets.ImageFolder(root = './data/kcar_edge/lights', transform = trans)\n",
    "# edge_test_sets = torchvision.datasets.ImageFolder(root = './data/kcar_edge/darks', transform = trans)\n",
    "train_sets = torchvision.datasets.ImageFolder(root = './data/kcar/lights', transform = trans)\n",
    "test_sets = torchvision.datasets.ImageFolder(root = './data/kcar/darks', transform = trans)\n",
    "labels = train_sets.classes\n",
    "print(len(edge_train_sets))\n",
    "print(len(edge_test_sets))\n",
    "print(len(train_sets))\n",
    "print(len(test_sets))\n",
    "print(len(labels))\n",
    "# print(test_sets)\n",
    "# print(edge_test_sets)\n",
    "\n",
    "# print(len(labels))\n",
    "# for i in range(4):\n",
    "#     img, label = train_sets[i]\n",
    "#     print(labels[label])\n",
    "#     plt.subplot(241 + i)\n",
    "#     plt.imshow(np.clip(img.permute(1,2,0),0,1))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    # save_image(img, str(i)+'_.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의 - data 길이 달라지면 random_t_list 수정하기!\n",
    "import random\n",
    "random_train_list = list(range(1, len(edge_train_sets)))\n",
    "random.shuffle(random_train_list)\n",
    "random_test_list = list(range(1, len(edge_test_sets)))\n",
    "random.shuffle(random_test_list)\n",
    "\n",
    "train_loader = DataLoader(train_sets, batch_size = 32, num_workers = 2, sampler = random_train_list)\n",
    "edge_train_loader = DataLoader(edge_train_sets, batch_size = 32, num_workers = 2, sampler = random_train_list)\n",
    "print(len(train_loader))\n",
    "test_loader = DataLoader(test_sets, batch_size = 32, sampler = random_test_list)\n",
    "edge_test_loader = DataLoader(edge_test_sets, batch_size = 32, sampler = random_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    " \n",
    "        _, pred = output.topk(maxk, 1, True, True) #(52, 32)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred)) # (5,32)\n",
    " \n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = torchvision.models.resnet101(pretrained=False)\n",
    "resnet101 = resnet101.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MyEnsemble 모델 학습 dark version\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,8], gamma=0.1)\n",
    "# learning_rate = 1e-4\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# hyper-parameters\n",
    "num_epochs = 10\n",
    "num_batches = 32\n",
    "\n",
    "resnet101.train()\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    trn_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, label = data\n",
    "\n",
    "        x = x.cuda()\n",
    "        label = label.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        model_output = resnet101(x)               \n",
    "        _, predicted = torch.max(model_output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "        # calculate loss\n",
    "        loss = criterion(model_output, label)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        \n",
    "        # 학습과정 출력\n",
    "        if (i+1) % 100 == 1: # every 100 mini-batches\n",
    "            resnet101.eval()\n",
    "            with torch.no_grad(): # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                val_total = 0\n",
    "                val_correct = 0\n",
    "                for j, (val) in enumerate(test_loader):\n",
    "                    val_x, val_label = val\n",
    "                    val_x = val_x.cuda()\n",
    "                    val_label =val_label.cuda()\n",
    "\n",
    "                    val_output = resnet101(val_x)\n",
    "                    _, predicted = torch.max(val_output.data, 1)\n",
    "                    val_total += val_label.size(0)\n",
    "                    val_correct += (predicted == val_label).sum().item()\n",
    "                    v_loss = criterion(val_output, val_label)\n",
    "                    val_loss += v_loss\n",
    "                    if epoch < 3:\n",
    "                        break\n",
    "                print(\"----------------testing data: \"+ str(j * len(test_loader)))\n",
    "                acc1, acc5 = accuracy(model_output, label, topk=(1, 5))\n",
    "                print(\"train acc1 : {}, acc5 : {}\".format(acc1[0], acc5[0])) \n",
    "                print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "\n",
    "                acc1, acc5 = accuracy(val_output, val_label, topk=(1, 5))\n",
    "                print(\"test acc1 : {}, acc5 : {}\".format(acc1[0], acc5[0]))\n",
    "                print('Accuracy of the network on the test images: %d %%' % (100 * val_correct / val_total))\n",
    "                       \n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch+1, num_epochs, i+1, len(train_loader), trn_loss / len(train_loader), val_loss / len(test_loader)\n",
    "            ))\n",
    "                    \n",
    "            \n",
    "            trn_loss_list.append(trn_loss/100)\n",
    "            val_loss_list.append(val_loss/len(test_loader))\n",
    "            trn_loss = 0.0\n",
    "            resnet101.train()\n",
    "        \n",
    "        # del (memory issue)\n",
    "        # del lossadw\n",
    "        del model_output\n",
    "    scheduler.step()\n",
    "#plotting the loss chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "torch.save(_, '모델 명(1)정확도 1(5)정확도 5.pt')\n",
    "# model1 = torch.load('model1.pt')"
   ]
  }
 ]
}